{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN2VS6C8zCdzUxQV3u4LcWN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduseiti/ia368v_dd_class_05/blob/main/LM_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Causal Language Model (CLM) fine-tuning\n",
        "\n",
        "This notebook executes the fine-tuning of **facebook/opt-125m** model, over the mc4 pt dataset samples prepared by the `LM_training_dataset_preparation.ipynb` notebook."
      ],
      "metadata": {
        "id": "jm10mcBmMyUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "IyoODiJf7UDV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_FOLDER=\"drive/MyDrive/unicamp/ia368v_dd/aula_05\"\n",
        "\n",
        "API_KEYS_FILE=\"/content/drive/MyDrive/unicamp/ia368v_dd/api_keys_20230324.json\"\n",
        "\n",
        "TRAIN_OUTPUT_FOLDER=\"./trained_model\"\n",
        "\n",
        "NORMALIZED_DATA_BLOCKS_PARTIAL_FILENAME=\"normalized_samples_block_*\""
      ],
      "metadata": {
        "id": "gB0nBfaiLYJC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import json"
      ],
      "metadata": {
        "id": "J1H5lQXWbFF5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(WORKING_FOLDER)"
      ],
      "metadata": {
        "id": "mFNsI1WXLtsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1088c923-e561-41a3-b960-539600e2aa13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(API_KEYS_FILE) as inputFile:\n",
        "#     api_keys = json.load(inputFile)\n",
        "\n",
        "# os.environ[\"COMET_API_KEY\"] = api_keys['comet_ml']\n",
        "# os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n",
        "# os.environ['COMET_MODE'] = \"ONLINE\""
      ],
      "metadata": {
        "id": "Exz2AKVDbGmK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from comet_ml import Experiment\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, default_data_collator, TrainerCallback\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union"
      ],
      "metadata": {
        "id": "2iEim9qqLRab"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "DcXd955oJhRE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "Iet6vPCwJhRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fded597e-2d67-48e5-939a-5fef09117383"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "44pKblR9uKJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534b0869-3d0b-4078-81b6-e089d392317f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 26 00:03:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME=\"facebook/opt-125m\""
      ],
      "metadata": {
        "id": "7k9UgWy7Wf77"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link to Comet ML reporting"
      ],
      "metadata": {
        "id": "c2pyJsxgHxCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment(api_key=api_keys['comet_ml'], \n",
        "#            project_name=\"causal-language-model-fine-tuning\",\n",
        "#            workspace=\"eduseiti\")"
      ],
      "metadata": {
        "id": "Rxf3Y8TjH0iB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the list of normalized-tokenized samples data blocked_samples\n",
        "\n",
        "The mc4 pt dataset sample has already been tokenized and size-normalized to 512, which is the model input size.\n",
        "\n",
        "Each data block contains a list of prepared samples, each of which can be directly fed to the model:\n",
        "\n",
        "```\n",
        "    {'input_ids': <list-of-512-tokens>,\n",
        "     'attention_masks': <list-of-512-attention-masks>}\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLsQX2lUwJtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_blocks = glob.glob(NORMALIZED_DATA_BLOCKS_PARTIAL_FILENAME)"
      ],
      "metadata": {
        "id": "eMIwdJE6wJyU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_blocks"
      ],
      "metadata": {
        "id": "_QGhlPPRwJ2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113ddf52-32e5-4cec-a3d6-c7bb79a026b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['normalized_samples_block_00.pkl',\n",
              " 'normalized_samples_block_01.pkl',\n",
              " 'normalized_samples_block_02.pkl',\n",
              " 'normalized_samples_block_03.pkl',\n",
              " 'normalized_samples_block_04.pkl',\n",
              " 'normalized_samples_block_05.pkl',\n",
              " 'normalized_samples_block_06.pkl',\n",
              " 'normalized_samples_block_07.pkl',\n",
              " 'normalized_samples_block_08.pkl',\n",
              " 'normalized_samples_block_09.pkl',\n",
              " 'normalized_samples_block_10.pkl',\n",
              " 'normalized_samples_block_11.pkl',\n",
              " 'normalized_samples_block_12.pkl',\n",
              " 'normalized_samples_block_13.pkl',\n",
              " 'normalized_samples_block_14.pkl',\n",
              " 'normalized_samples_block_15.pkl',\n",
              " 'normalized_samples_block_16.pkl',\n",
              " 'normalized_samples_block_17.pkl',\n",
              " 'normalized_samples_block_18.pkl',\n",
              " 'normalized_samples_block_19.pkl',\n",
              " 'normalized_samples_block_20.pkl',\n",
              " 'normalized_samples_block_21.pkl',\n",
              " 'normalized_samples_block_22.pkl',\n",
              " 'normalized_samples_block_23.pkl',\n",
              " 'normalized_samples_block_24.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the dataset class"
      ],
      "metadata": {
        "id": "SkHAtH-wMNV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples_blocks_filenames, fixed_data_block_index=None, sampling_size=None):\n",
        "        self.samples_blocks_filenames = samples_blocks_filenames\n",
        "\n",
        "        if fixed_data_block_index is not None:\n",
        "            self.current_file_index = fixed_data_block_index\n",
        "            self.change_file_index = False\n",
        "        else:\n",
        "            self.current_file_index = 0\n",
        "            self.change_file_index = True\n",
        "\n",
        "        with open(samples_blocks_filenames[self.current_file_index], \"rb\") as inputFile:\n",
        "            self.db = pickle.load(inputFile)\n",
        "\n",
        "        print(\"Dataset loading samples block {}; change_file_index={}...\".format(self.current_file_index, self.change_file_index))\n",
        "\n",
        "        self.sampling_size = sampling_size\n",
        "    \n",
        "        if self.sampling_size is not None:\n",
        "            self.dataset_size = self.sampling_size\n",
        "            self.sample_data()\n",
        "        else:\n",
        "            self.dataset_size = len(self.db)\n",
        "\n",
        "\n",
        "\n",
        "    def sample_data(self):\n",
        "        self.selected_samples = np.random.choice(list(range(len(self.db))), self.sampling_size, replace=False)\n",
        "        self.sampled_db = [self.db[i] for i in self.selected_samples]\n",
        "\n",
        "        print(\"Updating the sampled dataset itens; sample DB size: {}\".format(len(self.sampled_db)))\n",
        "\n",
        "\n",
        "\n",
        "    def update_dataset(self):\n",
        "        if self.change_file_index:\n",
        "            self.current_file_index = (self.current_file_index + 1) % len(self.samples_blocks_filenames)\n",
        "\n",
        "            with open(self.samples_blocks_filenames[self.current_file_index], \"rb\") as inputFile:\n",
        "                self.db = pickle.load(inputFile)\n",
        "\n",
        "            print(\"Updating dataset loading samples block {}; change_file_index={}...\".format(self.current_file_index, self.change_file_index))\n",
        "\n",
        "        if self.sampling_size is not None:\n",
        "            self.sample_data()\n",
        "        else:\n",
        "            self.dataset_size = len(self.db)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if self.sampling_size is not None:\n",
        "            return {'input_ids': self.sampled_db[idx]['input_ids'],\n",
        "                    'attention_mask': self.sampled_db[idx]['attention_mask'],\n",
        "                    'labels': self.sampled_db[idx]['input_ids'].copy()}\n",
        "        else:\n",
        "            return {'input_ids': self.db[idx]['input_ids'],\n",
        "                    'attention_mask': self.db[idx]['attention_mask'],\n",
        "                    'labels': self.db[idx]['input_ids'].copy()}"
      ],
      "metadata": {
        "id": "pk90h5aDx2q2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a callback to update the datasets"
      ],
      "metadata": {
        "id": "8sJYGLVq3sJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetUpdaterCallback(TrainerCallback):\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        train_dataset.update_dataset()\n",
        "        eval_dataset.update_dataset()"
      ],
      "metadata": {
        "id": "4zE1D83l2vYN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data"
      ],
      "metadata": {
        "id": "WpuFpHXyN-cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(data_blocks[:-1], sampling_size=3000)"
      ],
      "metadata": {
        "id": "ZJc4Ak_H5tw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fb232b-61ff-461e-97c7-a36714ed537c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loading samples block 0; change_file_index=True...\n",
            "Updating the sampled dataset itens; sample DB size: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = Dataset(data_blocks, len(data_blocks) - 1, sampling_size=1000)"
      ],
      "metadata": {
        "id": "Dp8cjYTZ-VJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f232160-1edd-4ee1-8382-64aa1e149062"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loading samples block 24; change_file_index=False...\n",
            "Updating the sampled dataset itens; sample DB size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the model"
      ],
      "metadata": {
        "id": "Awzi5Ads5J6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
        "print('Parameters', model.num_parameters())"
      ],
      "metadata": {
        "id": "g1QZgeFy58CM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15eb984-d0b9-434b-c1e6-e8f0f1a43737"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 125239296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the trainer"
      ],
      "metadata": {
        "id": "PrOgu5k96LTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=14"
      ],
      "metadata": {
        "id": "kT5rUueI658D"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params = TrainingArguments(output_dir=TRAIN_OUTPUT_FOLDER,\n",
        "                                    num_train_epochs=100,\n",
        "                                    per_device_train_batch_size=batch_size,\n",
        "                                    per_device_eval_batch_size=batch_size,\n",
        "                                    evaluation_strategy='epoch',\n",
        "                                    save_strategy='epoch',\n",
        "                                    logging_strategy='steps',\n",
        "                                    logging_steps=10,\n",
        "                                    save_total_limit=10,\n",
        "                                    # report_to='comet_ml',\n",
        "                                    learning_rate=2e-4,\n",
        "                                    weight_decay=1e-2,\n",
        "                                    dataloader_num_workers=4,\n",
        "                                    dataloader_pin_memory=False,\n",
        "                                    optim='adamw_torch',\n",
        "                                    fp16=True)"
      ],
      "metadata": {
        "id": "99L0Mq_p7s4M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_callback = DatasetUpdaterCallback()"
      ],
      "metadata": {
        "id": "phSscTZI3hO4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model,\n",
        "                     args=training_params,\n",
        "                     train_dataset=train_dataset,\n",
        "                     eval_dataset=eval_dataset,\n",
        "                     callbacks=[trainer_callback]\n",
        "                     )"
      ],
      "metadata": {
        "id": "77Sgz4OB8nMp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "OTFtBSwwgKdu",
        "outputId": "d69fadb1-0c45-46d6-b532-3f903c1181a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='253' max='21500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  253/21500 03:22 < 4:45:48, 1.24 it/s, Epoch 1.17/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.794500</td>\n",
              "      <td>2.785501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating dataset loading samples block 1; change_file_index=True...\n",
            "Updating the sampled dataset itens; sample DB size: 3000\n",
            "Updating the sampled dataset itens; sample DB size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "PgwWpgyIgaO6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}